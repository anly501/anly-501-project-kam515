{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Crawl example\n",
    "\n",
    "Author: J. Hickman\n",
    "\n",
    "- This code crawls through wikipedia to get a bunch of text data\n",
    "- The code lets the user specify search category topics.\n",
    "  - The more different the topics are, the easier the classification will be.\n",
    "  - For example, i used (pizza, metallurgy, basketball)\n",
    "- It then searches wikipedia for articles related to these topics\n",
    "- Loops over the wikipedia pages and gets the text from the wikipedia pages\n",
    "- Breaks the text into chunks (based on a user input specifying the number of sentences per chunk)\n",
    "- Each chunk is cleaned and tagged with a \"label\" (classification) and a numeric \"sentiment score\" (regression)\n",
    "- These cleaned chunks form a corpus of strings with associated tags\n",
    "\n",
    "```\n",
    "python -m pip install wikipedia_sections\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ANLY501/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# conda install -c conda-forge wikipedia\n",
    "# conda install -c conda-forge wordcloud\n",
    "# pip install wikipedia_sections\n",
    "\n",
    "import wikipedia\n",
    "import nltk\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/katherinemead/nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/katherinemead/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/katherinemead/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/katherinemead/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THE FOLLOWING IF YOU HAVEN'T DOWNLOADED THESE BEFORE\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/katherinemead/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set user parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS \n",
    "label_list=['school district','school takeover','education reform']\n",
    "max_num_pages=25\n",
    "sentence_per_chunk=5\n",
    "min_sentence_length=20\n",
    "\n",
    "# GET STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# INITALIZE STEMMER+LEMITZIZER+SIA\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define text cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text):\n",
    "\t# #FILTER OUT UNWANTED CHAR\n",
    "\tnew_text=\"\"\n",
    "\tkeep=string.printable\n",
    "\tkeep=\" abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "\tfor character in text:\n",
    "\t\tif character.lower() in keep:\n",
    "\t\t\tnew_text+=character.lower()\n",
    "\t\telse: \n",
    "\t\t\tnew_text+=\" \"\n",
    "\ttext=new_text\n",
    "\t# print(text)\n",
    "\n",
    "\t# #FILTER OUT UNWANTED WORDS\n",
    "\tnew_text=\"\"\n",
    "\tfor word in nltk.tokenize.word_tokenize(text):\n",
    "\t\tif word not in nltk.corpus.stopwords.words('english'):\n",
    "\t\t\t#lemmatize \n",
    "\t\t\ttmp=lemmatizer.lemmatize(word)\n",
    "\t\t\t# tmp=stemmer.stem(tmp)\n",
    "\n",
    "\t\t\t# update word if there is a change\n",
    "\t\t\t# if(tmp!=word): print(tmp,word)\n",
    "\t\t\t\n",
    "\t\t\tword=tmp\n",
    "\t\t\tif len(word)>1:\n",
    "\t\t\t\tif word in [\".\",\",\",\"!\",\"?\",\":\",\";\"]:\n",
    "\t\t\t\t\t#remove the last space\n",
    "\t\t\t\t\tnew_text=new_text[0:-1]+word+\" \"\n",
    "\t\t\t\telse: #add a space\n",
    "\t\t\t\t\tnew_text+=word.lower()+\" \"\n",
    "\ttext=new_text.strip()\n",
    "\treturn text\n",
    "\n",
    "# clean_string('the word \"pizza\" first appeared in a Latin text from the town of Gaeta, then still part of the Byzantine Empire, in 997 AD; the text states that a tenant of certain property is to give the bishop of Gaeta duodecim pizze (\"twelve pizzas\") every Christmas Day, and another twelve every Easter Sunday.Suggested etymologies include:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preform a wikipedia crawl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages for label = school district : ['School district', 'List of school districts in Arizona', 'Robb Elementary School shooting', 'School uniform', 'Lockport, Illinois', 'Vacaville, California', 'List of school districts in California', 'School District of Philadelphia', 'Tinker v. Des Moines Independent Community School District', 'Bethel School District v. Fraser', 'List of Long Island public school districts and schools', 'School discipline', 'Homewood-Flossmoor High School', 'List of the largest school districts in the United States by enrollment', 'School bus', 'Magnet school', 'Kennedy v. Bremerton School District', 'Hollywood High School', 'District', 'Hazelwood School District v. Kuhlmeier', 'Los Angeles Unified School District', 'Unified school district', 'Norwalk–La Mirada Unified School District', 'Frisco Independent School District', 'Chicago Public Schools']\n",
      "\t School district\n",
      "\t List of school districts in Arizona\n",
      "\t Robb Elementary School shooting\n",
      "\t School uniform\n",
      "WARNING: SOMETHING WENT WRONG: School uniform\n",
      "\t Lockport, Illinois\n",
      "\t Vacaville, California\n",
      "\t List of school districts in California\n",
      "\t School District of Philadelphia\n",
      "\t Tinker v. Des Moines Independent Community School District\n",
      "WARNING: SOMETHING WENT WRONG: Tinker v. Des Moines Independent Community School District\n",
      "\t Bethel School District v. Fraser\n",
      "\t List of Long Island public school districts and schools\n",
      "\t School discipline\n",
      "\t Homewood-Flossmoor High School\n",
      "WARNING: SOMETHING WENT WRONG: Homewood-Flossmoor High School\n",
      "\t List of the largest school districts in the United States by enrollment\n",
      "\t School bus\n",
      "WARNING: SOMETHING WENT WRONG: School bus\n",
      "\t Magnet school\n",
      "\t Kennedy v. Bremerton School District\n",
      "\t Hollywood High School\n",
      "\t District\n",
      "\t Hazelwood School District v. Kuhlmeier\n",
      "\t Los Angeles Unified School District\n",
      "\t Unified school district\n",
      "\t Norwalk–La Mirada Unified School District\n",
      "\t Frisco Independent School District\n",
      "\t Chicago Public Schools\n",
      "Pages for label = school takeover : ['Beslan school siege', 'Reverse takeover', 'School District of Philadelphia', 'Little Miss Geek', \"Sexey's School\", 'The Takeover UK', 'Paul Bilzerian', 'Richard P. Mills (educator)', 'Pat McAfee', 'Adrian Fenty', 'Proposed acquisition of Twitter by Elon Musk', 'The Takeover (novel)', 'Muriel Bowser', 'History of Washington, D.C.', 'Mayor of the District of Columbia', 'Trojan Horse scandal', 'CEO of public schools', 'Bette Midler', '2021 Taliban offensive', 'Michael A. Brown (Washington, D.C., politician)', 'Public Investment Fund', 'Gary Community School Corporation', 'Boston Public Schools', 'Southern Baptist Convention conservative resurgence', 'Shareholder rights plan']\n",
      "\t Beslan school siege\n",
      "\t Reverse takeover\n",
      "\t School District of Philadelphia\n",
      "\t Little Miss Geek\n",
      "\t Sexey's School\n",
      "\t The Takeover UK\n",
      "\t Paul Bilzerian\n",
      "\t Richard P. Mills (educator)\n",
      "\t Pat McAfee\n",
      "WARNING: SOMETHING WENT WRONG: Pat McAfee\n",
      "\t Adrian Fenty\n",
      "\t Proposed acquisition of Twitter by Elon Musk\n",
      "\t The Takeover (novel)\n",
      "\t Muriel Bowser\n",
      "\t History of Washington, D.C.\n",
      "\t Mayor of the District of Columbia\n",
      "\t Trojan Horse scandal\n",
      "WARNING: SOMETHING WENT WRONG: Trojan Horse scandal\n",
      "\t CEO of public schools\n",
      "\t Bette Midler\n",
      "WARNING: SOMETHING WENT WRONG: Bette Midler\n",
      "\t 2021 Taliban offensive\n",
      "\t Michael A. Brown (Washington, D.C., politician)\n",
      "\t Public Investment Fund\n",
      "\t Gary Community School Corporation\n",
      "\t Boston Public Schools\n",
      "\t Southern Baptist Convention conservative resurgence\n",
      "\t Shareholder rights plan\n",
      "Pages for label = education reform : ['Education reform', 'Education in China', 'Outcome-based education', 'Education in the United Kingdom', 'Education Reform Act', 'Traditional education', 'Education', 'Education policy', 'Reform', 'Reform (think tank)', 'Secondary education', 'Education Reform in Kentucky', 'Education Reform Act 1988', 'Democrats for Education Reform', 'Center for Education Reform', 'Standards-based education reform in the United States', 'Constructivism (philosophy of education)', 'Prussian education system', 'Education in Vietnam', 'Grading in education', 'Education in Mexico', 'Education in Japan', 'Secondary education in Japan', 'Reed Hastings', 'Higher-order thinking']\n",
      "\t Education reform\n",
      "\t Education in China\n",
      "\t Outcome-based education\n",
      "\t Education in the United Kingdom\n",
      "\t Education Reform Act\n",
      "WARNING: SOMETHING WENT WRONG: Education Reform Act\n",
      "\t Traditional education\n",
      "\t Education\n",
      "\t Education policy\n",
      "\t Reform\n",
      "WARNING: SOMETHING WENT WRONG: Reform\n",
      "\t Reform (think tank)\n",
      "\t Secondary education\n",
      "\t Education Reform in Kentucky\n",
      "\t Education Reform Act 1988\n",
      "\t Democrats for Education Reform\n",
      "\t Center for Education Reform\n",
      "\t Standards-based education reform in the United States\n",
      "\t Constructivism (philosophy of education)\n",
      "\t Prussian education system\n",
      "\t Education in Vietnam\n",
      "\t Grading in education\n",
      "\t Education in Mexico\n",
      "\t Education in Japan\n",
      "\t Secondary education in Japan\n",
      "\t Reed Hastings\n",
      "\t Higher-order thinking\n",
      "WARNING: SOMETHING WENT WRONG: Higher-order thinking\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZE \n",
    "corpus=[]  # list of strings (input variables X)\n",
    "targets=[] # list of targets (labels or response variables Y)\n",
    "\n",
    "#--------------------------\n",
    "# LOOP OVER TOPICS \n",
    "#--------------------------\n",
    "for label in label_list:\n",
    "\n",
    "\t#SEARCH FOR RELEVANT PAGES \n",
    "\ttitles=wikipedia.search(label,results=max_num_pages)\n",
    "\tprint(\"Pages for label =\",label,\":\",titles)\n",
    "\n",
    "\t#LOOP OVER WIKI-PAGES\n",
    "\tfor title in titles:\n",
    "\t\ttry:\n",
    "\t\t\tprint(\"\t\",title)\n",
    "\t\t\twiki_page = wikipedia.page(title, auto_suggest=True)\n",
    "\n",
    "\t\t\t# LOOP OVER SECTIONS IN ARTICLE AND GET PAGE TEXT\n",
    "\t\t\tfor section in wiki_page.sections:\n",
    "\t\t\t\ttext=wiki_page.section(section); #print(text)\n",
    "\n",
    "\t\t\t\t#BREAK IN TO SENTANCES \n",
    "\t\t\t\tsentences=nltk.tokenize.sent_tokenize(text)\n",
    "\t\t\t\tcounter=0\n",
    "\t\t\t\ttext_chunk=''\n",
    "\n",
    "\t\t\t\t#LOOP OVER SENTENCES \n",
    "\t\t\t\tfor sentence in sentences:\n",
    "\t\t\t\t\tif len(sentence)>min_sentence_length:\n",
    "\t\t\t\t\t\tif(counter%sentence_per_chunk==0 and counter!=0):\n",
    "\t\t\t\t\t\t\t# PROCESS COMPLETED CHUNK \n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# CLEAN STRING\n",
    "\t\t\t\t\t\t\ttext_chunk=clean_string(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t# REMOVE LABEL IF IN STRING (MAKES IT TOO EASY)\n",
    "\t\t\t\t\t\t\ttext_chunk=text_chunk.replace(label,\"\")\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t# REMOVE ANY DOUBLE SPACES\n",
    "\t\t\t\t\t\t\ttext_chunk=' '.join(text_chunk.split()).strip()\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE CORPUS \n",
    "\t\t\t\t\t\t\tcorpus.append(text_chunk)\n",
    "\n",
    "\t\t\t\t\t\t\t#UPDATE TARGETS\n",
    "\t\t\t\t\t\t\tscore=sia.polarity_scores(text_chunk)\n",
    "\t\t\t\t\t\t\ttarget=[label,score['compound']]\n",
    "\t\t\t\t\t\t\ttargets.append(target)\n",
    "\n",
    "\t\t\t\t\t\t\t#print(\"TEXT\\n\",text_chunk,target)\n",
    "\n",
    "\t\t\t\t\t\t\t# RESET CHUNK FOR NEXT ITERATION \n",
    "\t\t\t\t\t\t\ttext_chunk=sentence\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\ttext_chunk+=sentence\n",
    "\t\t\t\t\t\t#print(\"--------\\n\", sentence)\n",
    "\t\t\t\t\t\tcounter+=1\n",
    "\n",
    "\t\texcept:\n",
    "\t\t\tprint(\"WARNING: SOMETHING WENT WRONG:\", title);  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of text chunks =  970\n",
      "number of targets =  970\n",
      "                                                  text             label  \\\n",
      "0    12 public school function unit local usually o...   school district   \n",
      "1    controlling law varies united state operate in...   school district   \n",
      "2    power tax spend generally limited independent ...   school district   \n",
      "3    school board may also exercise quasi judicial ...   school district   \n",
      "4    outside united state autonomous district equiv...   school district   \n",
      "..                                                 ...               ...   \n",
      "965  hastings born boston massachusetts father wilm...  education reform   \n",
      "966  hastings first job adaptive technology created...  education reform   \n",
      "967  company growth proved challenging hastings lac...  education reform   \n",
      "968  1997 hastings former pure software employee ma...  education reform   \n",
      "969  selling pure software hastings found without g...  education reform   \n",
      "\n",
      "     sentiment  \n",
      "0       0.6369  \n",
      "1       0.5106  \n",
      "2       0.8442  \n",
      "3       0.5684  \n",
      "4       0.9468  \n",
      "..         ...  \n",
      "965     0.7003  \n",
      "966     0.8481  \n",
      "967     0.4404  \n",
      "968     0.4215  \n",
      "969    -0.3309  \n",
      "\n",
      "[970 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#SANITY CHECKS AND PRINT TO FILE \n",
    "print(\"number of text chunks = \",len(corpus))\n",
    "print(\"number of targets = \",len(targets))\n",
    "\n",
    "tmp=[]\n",
    "for i in range(0,len(corpus)):\n",
    "    tmp.append([corpus[i],targets[i][0],targets[i][1]])\n",
    "df=pd.DataFrame(tmp)\n",
    "df=df.rename(columns={0: \"text\", 1: \"label\", 2: \"sentiment\"})\n",
    "print(df)\n",
    "df.to_csv('wiki-crawl-results.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index = 0 : label = school district\n",
      "index = 1 : label = school takeover\n",
      "index = 2 : label = education reform\n",
      "number of text chunks =  970\n",
      "970\n",
      "['12 public school function unit local usually operate several school largest urban suburban district operate hundred school practice varies significantly state case within state american operate independent local governmental unit grant authority within geographic limit created state law executive legislative power locally controlled policy operation independent case held board education depending state law member local board education often referred informally school board may elected appointed political office holder serve ex officio combination independent legally separate body corporate political', 'controlling law varies united state operate independent local governmental unit exclusive authority 12 public educational operation policy extent control set state level law litigation common law firm specialize school law handle litigation paid school board professional liability insurance independent often exercise authority school system analogous authority local government like town county include power enter contact eminent domain power issue binding rule regulation affecting school policy operation', 'power tax spend generally limited independent annual budget may require approval plebiscite much new york local government additionally independent taxation authority may may exist virginia whose school division taxing authority must depend another local government county city town funding governing body typically elected direct popular vote may appointed governmental official called school board board trustee board education school committee like body appoints superintendent school usually experienced public school administrator function district chief executive carrying day day decision policy implementation']\n",
      "(970, 10943) (970,) (970,)\n"
     ]
    }
   ],
   "source": [
    "# #RELOAD FILE AND PRETEND THAT IS OUR STARTING POINT \n",
    "df=pd.read_csv('wiki-crawl-results.csv')  \n",
    "# #print(df)\n",
    "\n",
    "# #CONVERT FROM STRING LABELS TO INTEGERS \n",
    "labels=[]; #y1=[]; y2=[]\n",
    "y1=[]\n",
    "for label in df[\"label\"]:\n",
    "    if label not in labels:\n",
    "        labels.append(label)\n",
    "        print(\"index =\",len(labels)-1,\": label =\",label)\n",
    "    for i in range(0,len(labels)):\n",
    "        if(label==labels[i]):\n",
    "            y1.append(i)\n",
    "y1=np.array(y1)\n",
    "\n",
    "# # CONVERT DF TO LIST OF STRINGS \n",
    "corpus=df[\"text\"].to_list()\n",
    "y2=df[\"sentiment\"].to_numpy()\n",
    "\n",
    "print(\"number of text chunks = \",len(corpus))\n",
    "print(len(y1))\n",
    "print(corpus[0:3])\n",
    "\n",
    "# # INITIALIZE COUNT VECTORIZER\n",
    "vectorizer=CountVectorizer()   \n",
    "\n",
    "# # RUN COUNT VECTORIZER ON OUR COURPUS \n",
    "Xs  =  vectorizer.fit_transform(corpus)   \n",
    "X=np.array(Xs.todense())\n",
    "\n",
    "# #CONVERT TO ONE-HOT VECTORS\n",
    "maxs=np.max(X,axis=0)\n",
    "X=np.ceil(X/maxs)\n",
    "\n",
    "# # DOUBLE CHECK \n",
    "print(X.shape,y1.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f75bc8446c94e3689055a18017573334e0a773cb1d1589a7fad01c467977f447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
